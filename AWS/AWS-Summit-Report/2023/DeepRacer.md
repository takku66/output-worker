# DeepRacerのワークショップに参加してきた
## 感想
- 教師あり学習や教師なし学習については、過去に１度オンラインセミナーで聞いたり触ったりしたことがあるため、イメージは湧いていたが、強化学習については、フローのイメージが湧いていなかった。
- 今回の参加で、機械が自分で学習していく過程を知り、自分たちが強化学習に触れるにあたり、何を考え準備する必要があるのかを知ることができた。
- 面白かった。

## DeepRacerとは
- クラウドベースの 3D レーシングシミュレーター。
- AWSのミッションである、全ての開発者の手にどのようにして強化学習を提供できるかを考えて登場した、らしい。

## 強化学習とは
- 期待された行いに対して、報酬を与える。
- ペットが良い行いをした時に、餌をあげることが典型的。

### 用語
- エージェント
  - ゴールに向かう機械やソフトウェア
- 環境
  - DeepRacerの場合は、トラックにあたる。
- 状態
  - エージェントからみた環境のこと。
  - カメラ画像やセンサーから得られる状態。
- 行動
  - ゴールに向かうための行動
- 報酬
  - 取った行動に対しての報酬
- エピソード
  - スタートからゴールまでのエージェントの一連の行動

# 報酬関数
- 強化学習のコアであり、いかにこの報酬関数を定義するかが重要となる。

# やってみる
- 後日記載

# 個人的な解釈
- 報酬関数は、エージェントの最終的な学習成果の質を高めるために必要なもの。
- 適切な報酬関数は、より最適だと評価される経路を走ることができる。
- 行動空間は、エージェントが効率的に学習をするために定義する。
- 本来ありえない行動や、起こり得ないことを予め制限しておくことで、試行錯誤を繰り返す中でも、質の高い探索をすることができる。


# ワークショップ
- AWS DeepRacerの公式ドキュメント
https://docs.aws.amazon.com/ja_jp/deepracer/latest/developerguide/deepracer-reward-function-input.html
- ワークショップのURL  
https://catalog.workshops.aws/deepracer-200l/ja-JP

